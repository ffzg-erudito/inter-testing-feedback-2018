\documentclass[../main.tex]{subfiles}

\begin{document}

The aim of this study was to explore the effects of different interpolated  
activities and feedback reception on learning complex materials. We found 
evidence for an effect of interpolated activity type on TPNL — treating the 
two dependent variables as manifestations of TPNL, we conducted a MANOVA, 
revealing that participants engaging in episodic retrieval exhibited greater 
TPNL than both participants who engaged in semantic retrieval and those in 
the control condition. Moreover, a Roy-Bargmann stepdown analysis showed 
that observed differences were driven primarily by the number of correct 
responses, while finding no evidence for the contribution of PI.

The fact that we observed the effect of interest while employing a testing 
format which is known to produce the smallest effects is interesting in and 
of itself, and suggests that the effect should hold in conditions that are 
arguably the most prevalent in western educational systems. Nevertheless, 
our results are not entirely in line with extant research nor with the 
context change account of TPNL. While our results point to an exclusive role 
of episodic retrieval, \cite{pastotterRetrievalLearningFacilitates2011}, for 
example, found that both types of retrieval can generate TPNL. Notably, 
these authors used simpler learning materials and free recall — both 
learning material complexity and testing format are known moderators of TPNL 
\citep{chanRetrievalPotentiatesNew2018}. However, the few studies that 
examined the effects of nonepisodic recall on TPNL have produced equivocal 
results. While two studies suggested that nonepisodic and episodic recall 
have comparable effects \citep{divisRetrievalSpeedsContext2014, 
pastotterRetrievalLearningFacilitates2011}, 
\cite{weinsteinNotAllRetrieval2015} failed to show this. Among a number of 
methodological differences between these studies, the specific type of 
nonepisodic recall stands out as a possible reason behind the diverging 
results. While \cite{pastotterRetrievalLearningFacilitates2011} and 
\cite{divisRetrievalSpeedsContext2014} both used semantic generation, 
\cite{weinsteinNotAllRetrieval2015} used recall from autobiographical 
memory. Delineating the potential distinctive effects various forms of 
non-episodic recall could have in the TPNL paradigm is a goal future studies 
may pursue.

Studies that have suggested that nonepisodic recall may serve as an effective
method of learning potentiation have drawn on context theories to explain 
their results \citep{divisRetrievalSpeedsContext2014, 
pastotterRetrievalLearningFacilitates2011}. 
\cite{divisRetrievalSpeedsContext2014} proposed that retrieval processes 
enhance context fluctuation, thereby increasing the segregation between 
information acquired across study sessions. This, in turn, reduces 
the memory search set and PI. Having said that, they acknowledged that other 
encoding-based explanations such as encoding strategy optimisation or 
encoding resetting were not ruled out. In our study, the absence of an 
effect of nonepisodic retrieval on learning may be taken as evidence 
against a context change account of TPNL because, presumably, retrieval from 
semantic memory should have produced the necessary internal context change 
\citep{pastotterRetrievalLearningFacilitates2011}. A Bayesian estimate of 
the effect of nonepisodic recall also lends support for the claim that it 
does not enhance learning (see supplementary materials). Notably, a basic 
assumption we have made is that the interpolated activity that served the 
function of activating retrieval from semantic memory in our study was 
effective.

If a context change account is inapplicable to our results, then it is 
unsurprising that feedback, which we proposed could enhance context 
fluctuations, proved completely ineffective in the nonepsidic recall 
condition. While we found no evidence for an effect of feedback, 
exploratory Bayesian analyses do not exclude the possibility of one, but the 
obtained estimates point to an effect which could be practically equivalent 
to zero. Interpreting these results warrants caution, though, since a more 
precise estimate of the effect is desirable. Assuming the effect of 
feedback was in fact insignificant, this may have occurred because 
content-related questions in and of themselves gave participants the 
information they required in order to adjust their encoding strategy, 
thereby rendering redundant the otherwise positive influence of explicit 
feedback \citep{roedigeriiiPowerTestingMemory2006, 
kornellUnsuccessfulRetrievalAttempts2009}. 

Recently, \cite{chanRetrievalPotentiatesNew2018} provided a meta-analysis 
and comprehensive overview of the literature, identifying several 
viable explanations for TPNL. Besides context theories, whose main points 
are outlined above, \textit{resource theories} generally posit that testing 
increases cognitive resources either by (i) reducing encoding-based PI (e.g. 
\citealp{wahlheimTestingCanCounteract2015, 
	weinsteinTestingProtectsProactive2011, szpunarTestingStudyInsulates2008, 
	nunesTestingImprovesTrue2012}), (ii) restoring encoding/attentional 
resources (e.g. \citealp{pastotterRetrievalLearningFacilitates2011}), or by 
(iii) altering mind wandering patterns to focus them more on the learning 
material (e.g. \citealp{jingInterpolatedTestingInfluences2016, 
	szpunarInterpolatedMemoryTests2013,szpunarMindWanderingEducation2013}).
A circumscription of separate learning episodes is at the core of both 
resource and context accounts, but its effect on learning is different 
depending on the outlook. According to the former, isolating a learning 
episode through attempts at recall increases resources for subsequent 
learning by preventing \textit{encoding-based} PI. On the other hand, 
context theories emphasise later \textit{retrieval} processes, whereby 
isolating an earlier learning episode reduces the memory search set for 
retrieval. From our data we gather that even a hybrid account, where 
internal context shifts increase resources by resetting encoding processes 
\citep{pastotterRetrievalLearningFacilitates2011}, is not a suitable 
explanation.

While resource theories revolve around the amount of deployable cognitive 
resources, \textit{metacognitive theories} emphasise the optimisation of 
their deployment, regardless of their amount. Thus, using metacognitive 
knowledge gained through retrieval attempts (e.g. 
\citealp{choTestingEnhancesBoth2017, 
	chanTestingPotentiatesNew2018}), and perhaps even failures of retrieval 
\citep{bahrickImportanceRetrievalFailures2005}, learners can adjust their 
strategies. We believe this to be the most fitting explanation for our data 
\citep{wissmanInterimTestEffect2011, 
	chanTestingPotentiatesNew2018}. In our study, only those participants
who gained familiarity with the questions and type of knowledge the final 
test would assess were thus given the opportunity to evaluate their encoding 
strategies and to modify them accordingly. Ultimately, only they 
demonstrated an increase in the number of correct answers on the final 
critical test. 

In line with these proposals, recent studies have shown that retrieval 
modifies the learner's approach to new information 
\citep{choTestingEnhancesBoth2017, 
soderstromTestingFacilitatesRegulation2014}, which may even lead to
superior semantic organisation of acquired knowledge 
\citep{chanTestingPotentiatesNew2018, 
	jingInterpolatedTestingInfluences2016}, which is also of central
importance for \textit{integration theories} of TPNL 
\citep{chanRetrievalPotentiatesNew2018}. For example, in a 
recent investigation using multi-list learning, 
\cite{chanTestingPotentiatesNew2018} found that, compared to untested 
groups, the group subjected to interpolated testing displayed an increase in 
category-based clustering during free recall. They ascribe this to an 
adoption of more efficient encoding/retrieval strategies, which may activate 
other relevant learning processes such as relational processing. A similar 
pattern is often observed in studies exploring the testing effect, where a 
greater number of tests is associated with improved organisation of output 
displayed upon testing \citep{zarombTestingEffectFree2010, 
	karpickeRetrievalBasedLearningActive2012}. Importantly, the
accounts mentioned above are not mutually exclusive. One can easily imagine 
how a strategy shift could reduce PI and foster integration.

%Testing is thought to increase thelikelihood of spontaneous covert 
%retrieval of older items during the study of new ones, fostering their 
%integration, thereby increasing conceptual organisation (e.g. 
%\citealp{jingInterpolatedTestingInfluences2016}) and the effectiveness of 
%retrieval cues \citep{pycWhyTestingImproves2010}.For example, 
%\cite{jingInterpolatedTestingInfluences2016} found that interpolated 
%testing 
%increased the clustering of related information that is acquired 
%\textit{across} different segments within a video-recorded lecture.

Finally, we have to address certain methodological concerns.  In our study, 
participants were thoroughly informed regarding the activities they would 
encounter during the procedure, including the final test following the last 
reading episode. The typical instruction given to participants in the TPNL 
paradigm is that interpolated activities will be determined randomly
\citep{yangEnhancingLearningRetrieval2018}. Thus, an attempt is made to 
equalise expectations of a final test across conditions, and to ensure 
continued processing of materials across the study sequences. Nevertheless, 
learners dynamically adjust their expectations based on their experiences of 
the procedure, regardless of the instructions they are given 
\citep{weinsteinRoleTestExpectancy2014}.  If they take a test, they will 
more likely expect another one, and such expectations are known to influence 
encoding (e.g. \citealp{szpunarExpectationFinalCumulative2007}).

It is worth mentioning that our choice of learning materials could have 
prevented us from finding evidence in favour of context theories and an 
account based on the reduction of PI. However, previous work has shown that 
release from PI may play basically no role when it comes to learning complex 
materials \citep{divisRetrievalSpeedsContext2014, 
wissmanInterimTestEffect2011}. The recognition-level method which we 
employed showed no signs of PI beyond those expected to occur by chance 
alone. Admittedly, limiting the number of choices by displaying possible 
answers may have diluted the interference effect other unwritten pieces of 
information might have had, if we had used free recall instead.

Further, we cannot exclude the possibility that our interpolated activities 
had differential effects on our participants’ motivation. Several  
participants remarked that the text was tedious, and it is possible that the 
motivation of participants in the episodic retrieval condition persisted 
throughout the procedure, while that of the other participants waned as the 
procedure progressed. However, if this were true, we should have observed 
the lowest scores in the rereading group. Yet, this is not the case. 
Furthermore, we find no reason to believe that answering general knowledge 
questions is less interesting than answering questions about weeds, and 
presume that the former would, therefore, help sustain motivation. On the 
other hand, differences in engagement could have been caused by unequal task 
difficulties — the mean proportions of correctly answered questions are 
larger in the content-related than in the general-knowledge testing 
conditions. Importantly, the mean proportion of correct answers on the first 
interpolated content-related test is higher than on the second. If the tests 
were equally difficult, and if there had been a TPNL effect, we would expect 
higher scores on the second test. This points to the tentative conclusion 
that the interpolated tests themselves differed in difficulty. Thus, we 
cannot reject the possibility that differing difficulties affected our 
participants’ achievement. However, difficulty of the interpolated tasks 
does not appear to be of consequence in this matter 
\citep{divisRetrievalSpeedsContext2014, 
pastotterRetrievalLearningFacilitates2011, 
sahakyanContextChangeRetrieval2012}.

To conclude, our findings confirm the effect of episodic recall on TPNL, but 
we fail to find evidence for an effect of semantic recall. Further, evidence 
for an effect of feedback is also lacking. Our data are generally aligned 
with predictions stemming from metacognitive theories of TPNL, and speak 
against PI reduction accounts within the wider framework of resource 
theories.

\end{document}





%Szpunar (2008)
%In each of our experiments, participants expected a final test.
%Accordingly, they were likely to hold words in mind (across lists) as they 
%studied (Masson & McDaniel, 1981; Szpunar et al., 2007).
%Participants also knew that a test might follow the presentation of
%any list in the study sequence. Thus, although maintenance of all
%lists was important in the long term, subsequent lists in the study
%sequence had to be discriminated in anticipation of initial testing.
