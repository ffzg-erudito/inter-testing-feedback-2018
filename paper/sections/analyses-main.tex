% Options for packages loaded elsewhere
\begin{document}

\hypertarget{exclusion-criteria}{%
\subsection{Exclusion criteria}\label{exclusion-criteria}}

Prior to analysing the data, we excluded participants based on a priori
set criteria. Participants who spent less than or equal to 90 seconds on
the practice text were excluded (1 exclusion). Further, we wanted to
exclude participants who had no correct answers on the final test (0
exclusions). Finally, we excluded participants who had stated that they
had reading deficits (3 exclusions). This left us with a total sample of
203 participants.

\hypertarget{interpolated-activity-effect}{%
\subsection{Interpolated activity
effect}\label{interpolated-activity-effect}}

Our first two hypotheses are concerned with the effects of different
interpolated activities on the total number of correct answers and total
number of intrusive distractors chosen. To test these hypotheses, we
focused only on the groups which did not receive feedback (\(n\) = 122).
This was done because there was no feedback option for the rereading
group, and we did not want to treat the feedback and no-feedback
general-knowledge and content-related testing groups as equivalent
without strong evidence supporting that assumption.

The correlation between our DVs calculated on the whole sample is
\(r(201) =\) -.707 (95\% CI: {[}-.77, -.63{]}, \(p\) \textless{} .0001).
Given that we have two dependent variables, which are highly correlated,
we have decided to conduct a one-way MANOVA. According to
\citet{tabachnickUsingMultivariateStatistics2012}, conducting a MANOVA
instead of multiple ANOVAs increases the chance of discovering the
effects of different treatments. Furthermore conducting a MANOVA guards
against the inflation of Type 1 errors due to multiple tests of
correlated dependent variables
\citep{tabachnickUsingMultivariateStatistics2012,fieldDiscoveringStatisticsUsing2012}.
Finally, conducting separate ANOVAs would disregard the correlation
between our two dependent variables
\citep{fieldDiscoveringStatisticsUsing2012}. Therefore, we conducted a
one-way MANOVA with interpolated activity as the independent variable
and the total number of correct and intrusive options chosen as
dependent variables.

A power analysis conducted prior to analysing the data
\citep[using the G*Power software by][]{faulStatisticalPowerAnalyses2009}
has shown that we should have above 80\% power to detect effects which
fall between small and medium (Cohen's \(f^2\ \gtrsim 0.06\)), at an
\(\alpha\) level of .025, with a sample size of 110 participants. Note
that larger effects are expected based on prior studies.

Pillai's V for the analysis is .126, \(p = .004\) (Wilks' \(\Lambda\) =
.875, \(p = .003\)). The effect size, calculated as
\(\omega^2_{mult} = .109\) (bootstrap
median\footnote{All bootstrap estimates taken from 10000 replications.}
= .132, \(BC_\alpha\) 95\% CI = {[}.011, .202{]})\footnote{
Cohen's \(f^2 = 0.051\) (calculated according to Equation 12 in
\citealp{steynjrEstimatingEffectSize2009}).
}. To further inspect the relationship of the interpolated activities
with our dependent variables, we conducted a Roy-Bargmann stepdown
analysis, as suggested by
\citeauthor{tabachnickUsingMultivariateStatistics2012}
(\citeyear{tabachnickUsingMultivariateStatistics2012}; a linear
discriminant analysis with the same aim is available in the
supplementary materials). According to
\citet{tabachnickUsingMultivariateStatistics2012}, the higher priority
variable can be chosen based on theoretical or practical grounds. Since
the total number of correct answers is the criterion that determines a
student's success in a testing context, we chose this dependent variable
as the higher priority one. Therefore, we first conducted an ANOVA with
interpolated activity type as the independent variable and the total
number of correct answers as the dependent variable.

As could be expected, the ANOVA points to a differential effect of our
conditions on the total number of correct answers, with \(F(2, 119)\) =
7.541, \(p = .001\). Following the ANOVA, we conducted an ANCOVA, with
the total number of correct answers as the covariate, and the total
number of intrusors as the dependent variable. The results imply a main
effect of the total number of correct answers (\(F(1, 118)\) = 79.674,
\(p < .0001\)), but after we took into account the number of correct
answers, we found no evidence for an effect of interpolated activity
type on the total number of chosen intrusors (\(F (2, 118)\) = 0.844,
\(p = .433\)). So far, our analyses show a lack of evidence in support
of our second hypothesis that the type of interpolated activity will
have an effect on the number of intrusors.

In order to test our first hypothesis, we contrasted (i) the two test
groups with each other, and (ii) the rereading group with the two test
groups, taking only the total number of correct answers as the DV. We
found a difference between the two test groups (\(t(119)\) = 3.62,
\(p = .0004\), \(g_s\) = 0.66, 95\% CI = {[}0.21, 1.1{]}, Cohen's
\(U_{3, g_s}\) = 74.43\%, probability of superiority = 67.88\%).
Students in the content-related-test condition score higher on the final
test than students in the general-knowledge-test condition. The second
contrast shows no evidence of a difference between the rereading group
and the two test groups (\(t(119)\) = 1.355, \(p = .178\), \(g_s\) =
0.19, 95\% CI = {[}-0.19, 0.57{]}, Cohen's \(U_{3, g_s}\) = 57.6\%,
probability of superiority = 55.39\%). Therefore, we cannot conclude
that being in the rereading condition, as opposed to being in one of the
two test groups, leads to different learning outcomes. However, we
believe this is due to the rereading and general-knowledge-testing
groups having very similar mean numbers of correct answers
(\(M = 10.88\) and \(10.47\), respectively) These two findings are not
in line with our predictions.

\hypertarget{the-interaction-between-feedback-and-interpolated-activity-type}{%
\subsection{The interaction between feedback and interpolated activity
type}\label{the-interaction-between-feedback-and-interpolated-activity-type}}

The remaining hypotheses deal with the effect of feedback on the total
number of correct answers and the total number of intrusors. Therefore,
these analyses were carried out on the data from participants in the
general and content related test conditions only (\(n\) = 163). To test
these hypotheses, we first conducted a two-way MANOVA with interpolated
activity and feedback as independent variables, and total number of
correct answers and total number of intrusors as the dependent
variables. Again, a power analysis conducted before analysing the data
has shown that we should have above 80\% power to detect effects which
fall between small and medium (Cohen's \(f^2\ \gtrsim 0.05\)), at an
\(\alpha\) level of .025, with a sample size of 145 participants.

Pillai's V for the interpolated activity effect (calculated with type
III sums of squares) is .071, \(p = .003\) (Wilks' \(\Lambda\) = .929,
\(p = .003\)) confirming the main effect of interpolated activity type.
The effect size \(\omega^2_{mult}\) = .065 (bootstrap median = .072,
\(BC_\alpha\) 95\% CI = {[}.008, .140{]})\footnote{
Cohen's \(f^2 = 0.063\), using Equation 12 from
\citet{steynjrEstimatingEffectSize2009}.
}.

On the other hand, we found no evidence for an effect of giving feedback
on the linear combination of our two dependent variables --- Pillai's V
= .003, \(p = .800\) (Wilks' \(\Lambda\) = .997, \(p = .800\)). The
estimated effect size is \(\omega^2_{mult}\) = 0.

Furthermore, we found no evidence for an interaction effect between
activity type and feedback --- Pillai's V = .001, \(p = .941\) (Wilks'
\(\Lambda\) = .999, \(p = .941\)). The estimated effect size
\(\omega^2_{mult}\) = 0.

Again, we conducted a follow-up Roy-Bargmann stepdown analysis. In the
ANOVA model with the total number of correct answers as the dependent
variable and the type of interpolated activity, feedback and their
interaction as predictors, only the type of activity seems to be
relevant (\(F(1, 159) = 11.2, p = .001\)). This result also shows that
students in the content-related-test condition score higher on the final
test than students in the general-knowledge-test condition, which should
be no surprise given the results of the first stepdown analysis. In the
second step, we fit an ANCOVA model with the total number of correct
answers as the covariate. In this model, the type of interpolated
activity ceases to be a relevant predictor
(\(F(1, 155) = 0.175, p = .676\)). Therefore, we find no evidence for an
effect of the type of interpolated activity nor of feedback on the
number of intrusive distractors chosen. The full models are shown in
Table \ref{rb2-table}.

To summarise, contrary to our expectations, we find no evidence of an
effect of feedback on the total number of correctly answered questions.
Also, we found no evidence for an interaction effect of feedback and
type of interpolated activity on the total number of correct answers.
The same findings apply to the predictions regarding the total number of
intrusors chosen.

\end{document}
