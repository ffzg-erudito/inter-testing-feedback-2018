\documentclass[../main.tex]{subfiles}

\begin{document}

The term ``testing effect'' refers to the finding that, when it comes to 
long-term retention of a piece of information, retrieving it from memory 
trumps restudying it 
\citep{karpickeCriticalImportanceRetrieval2008,roedigeriiiPowerTestingMemory2006,
 roedigeriiiTestEnhancedLearningTaking2006, rowlandEffectTestingRestudy2014, 
adesopeRethinkingUseTests2017, roedigeriiiCriticalRoleRetrieval2011, 
gloverTestingPhenomenonNot1989}. Besides directly enhancing retention 
through repetition of successful retrieval --- a process which is, presumably, 
reactivated at the time of a later test --- testing effects can be brought 
about indirectly (\citealp{arnoldTestpotentiatedLearningDistinguishing2013, 
roedigeriiiPowerTestingMemory2006}; but for a different view, see 
\citealp{kornellRetrievalAttemptsEnhance2015}). For example, unsuccessful 
retrieval attempts can, through subsequent repeated encoding, generate 
test-potentiated (re)learning (TPL), whereby taking more tests increases the 
proportion of \textit{newly} retrieved items in a test immediately following a 
restudy episode 
\citealp{izawaReinforcementTestSequencesPairedAssociate1966,izawaOptimalPotentiatingEffects1970,
 kornellUnsuccessfulRetrievalAttempts2009, arnoldFreeRecallEnhances2013, 
arnoldTestpotentiatedLearningDistinguishing2013, 
wissmanTestpotentiatedLearningThree2018}).

After an initial impetus provided by 
\cite{szpunarTestingStudyInsulates2008}, who built upon earlier findings 
\citep{darleyEffectsPriorFree1971, tulvingNegativeTransferEffects1974}, a 
decade of research has shown that retrieving previously studied information 
can even facilitate the acquisition of \textit{new} information 
\citep{chanRetrievalPotentiatesNew2018, 
pastotterRetrievalPracticeEnhances2014, yangEnhancingLearningRetrieval2018}. 
If each subsequent study episode in the paradigm used to demonstrate TPL 
contains new materials (giving a now standard blocked design; 
\citealp{chanTestingPotentiatesNew2018}), one still observes that testing 
the memory for those new materials after each learning episode yields a 
greater number of correct responses and a decrease of proactive interference 
(PI) on a test administered to all subjects after the final learning episode 
(e.g. \citealp{szpunarInterpolatedMemoryTests2013, 
szpunarTestingStudyInsulates2008, wissmanInterimTestEffect2011}). Following 
the reasoning of \cite{chanRetrievalPotentiatesNew2018}, we use the term 
``test-potentiated \textit{new} learning'' (TPNL) to denote this effect.
With studies mainly using the multilist learning paradigm to delineate the 
scope of TPNL, a particularly important question for real-world applications 
is whether these results generalise to materials more complex than word 
lists, and research conducted in the preceding decade mostly points to a 
positive answer (prose passages: \citealp{wissmanInterimTestEffect2011, 
divisRetrievalSpeedsContext2014}; video lectures: 
\citealp{szpunarInterpolatedMemoryTests2013, 
jingInterpolatedTestingInfluences2016}). 

Recently, \cite{chanRetrievalPotentiatesNew2018} provided a meta-analytic 
analysis and comprehensive overview of the literature, identifying four 
\textit{nonconflicting} theoretical frameworks which were put forth throughout 
the years as viable explanations for TPNL. \textit{Resource theories} generally 
posit that testing increases cognitive resources, but they propose different 
mechanisms by which this is achieved: (i) proactive interference reduction 
(e.g. \citealp{wahlheimTestingCanCounteract2015, 
weinsteinTestingProtectsProactive2011, szpunarTestingStudyInsulates2008, 
nunesTestingImprovesTrue2012}), (ii) restoration of encoding/attentional 
resources (e.g. \citealp{pastotterRetrievalLearningFacilitates2011}), or (iii) 
alteration of mind wandering patterns (e.g. 
\citealp{jingInterpolatedTestingInfluences2016,szpunarInterpolatedMemoryTests2013,szpunarMindWanderingEducation2013}).
 Whereas resource theories focus on the amount of deployable cognitive 
resources, \textit{metacognitive theories} emphasise the optimisation of 
encoding strategies induced by retrieval attempts (e.g. 
\citealp{choTestingEnhancesBoth2017, chanTestingPotentiatesNew2018}). For 
example, in a recent investigation, \cite{chanTestingPotentiatesNew2018} found 
that, compared to untested groups, the group whose memory for the first three 
word lists was subjected to interpolated testing displayed superior semantic 
organisation across lists. These findigs reflect a similar pattern obtained for 
the testing effect, where a greater number of tests is associated with improved 
organisation of output displayed upon testing 
\citep{karpickeRetrievalBasedLearningActive2012,zarombTestingEffectFree2010}.

The key idea underlying the third framework --- \textit{context theories} --- 
is that, apart from storing the studied information themselves, people store 
the related contextual information as well (e.g. 
\citealp{lehmanEpisodicContextAccount2014}). Afterwards, the accessibility of 
this contextual information can affect the likelihood of successful retrieval 
of target information. Furthermore, the claim is that, unlike restudying, 
attempting retrieval causes an internal context change relative to the study 
context \citep{jangContextRetrievalContext2008, 
sahakyanContextualChangeAccount2002}, and recalled items may be updated with 
contextual information from the retrieval attempt, while newly encountered 
information is still associated only with the study context. Therefore, 
recalling new-learning items is limited to only those items associated 
exclusively with the study context, providing them with the advantage observed 
upon testing. While this circumscription of separate learning episodes is at 
the core of both resource and context accounts, its effect on learning is 
supposedly different. According to the former, isolating a learning episode 
through attempts at recall increases resources for subsequent learning by 
preventing \textit{encoding-based} proactive interference. On the other hand, 
the latter place the emphasis on later \textit{retrieval} processes, whereby 
isolating an earlier learning episode reduces the memory search set for 
retrieval.

Finally, \textit{integration theories} advance the notion that interpolated 
testing facilitates the integration of the new-learning material either with 
its retrieval cues or with the original-learning material. On one account, 
testing increases the likelihood of spontaneous covert retrieval of 
original-learning items during the study of new items, fostering their 
integration, thereby increasing conceptual organisation (e.g. 
\citealp{jingInterpolatedTestingInfluences2016}) and the effectiveness of 
retrieval cues \citep{pycWhyTestingImproves2010}. For example, 
\cite{jingInterpolatedTestingInfluences2016} found that interpolated testing 
increased the clustering of related information that is acquired across 
different segments within a video-recorded lecture.Summarising the results of 
their metaregression, \cite{chanRetrievalPotentiatesNew2018} highlighted 
resource and integration theories as accounts which have thus far garnered more 
empirical support, giving a slight upper hand to integration theories, while 
stating that context theories are least supported by extant research. 

\cite{chanRetrievalPotentiatesNew2018} conducted a metaregression, comparing 
the explanatory power of the four frameworks described above. Summarising their 
results, they highlighted resource and integration theories as accounts which 
have thus far garnered more empirical support, giving a slight upper hand to 
integration theories, while stating that context theories are least supported 
by extant research. However, the field requires more empirical investigations 
into the matter to gauge the validity of the accounts described above.

\hypertarget{nonepisodic}{%
\subsection{Nonepisodic recall}}

One of the more curious findings in the field is that TPNL can arise not 
only after retrieving the previously studied material (episodic retrieval), 
but also after retrieval of information unrelated to the studied material 
from semantic \citep{divisRetrievalSpeedsContext2014, 
pastotterRetrievalLearningFacilitates2011}, or short-term memory 
\citep{pastotterRetrievalLearningFacilitates2011}, although there have been 
unsuccessful attempts at replication (e.g. 
\citealp{weinsteinNotAllRetrieval2015}). 

\cite{pastotterRetrievalLearningFacilitates2011} let their participants learn 
five lists of 20 words while engaging in varied interlist activities. They 
either restudied the lists, recalled the words from the list, generated as many 
words as they could from one of four semantic categories (e.g. professions), 
engaged in a 2-back short-term memory task, or counted backwards from a random 
three-digit number. They found that all three forms of retrieval induced TPNL. 
In their first experiment, \cite{divisRetrievalSpeedsContext2014} adapted the 
procedure from \cite{pastotterRetrievalLearningFacilitates2011}, using only the 
semantic generation and distractor (counting backwards) tasks, and found that 
interleaved semantic retrieval enhanced performance for final list recall. They 
replicated and extended these findings in their second experiment by using 
complex learning materials: lists of words were replaced by texts related to 
animals, while learning was evaluated with short-answer and multiple-choice 
questions. 

The argument these two groups of authors invoke to explain their results is 
that nonepisodic retrieval tasks sufficiently alter participant's internal 
context. Because the last study session is not affected by an additional 
context shift, a beneficial segregation of the final study context from the 
previous ones is produced, which reduces the memory search set. If this is the 
case, 

\hypertarget{feedback}{%
\subsection{Feedback}}

Although corrective feedback is known to augment the testing effect 
\citep{roedigeriiiCriticalRoleRetrieval2011}, there is a paucity of research 
into the effect of feedback on TPNL. Feedback is particularly important for 
recognition tests such as multiple-choice tests since the usual benefit 
testing confers might turn into a disadvantage in case the test-taker 
selects a lure \citep{roedigerPositiveNegativeConsequences2005, 
marshMemorialConsequencesMultiplechoice2007}. Moreover, evidence points to 
the timing of feedback being a relevant variable when gauging its influence 
on learning, with delayed feedback given in bulk showing superior effects 
compared to immediate, piecemeal feedback 
\citep{metcalfeDelayedImmediateFeedback2009,butlerEffectTypeTiming2007, 
butlerFeedbackEnhancesPositive2008,smithLearningFeedbackSpacing2010}.
The variable of corrective feedback may be a fruitful avenue for research 
because resource and integration theories provide conflicting predictions 
regarding its effects on TPNL \citep{chanRetrievalPotentiatesNew2018}. 
Providing corrective feedback should increase the likelihood of intrusions 
during new learning, which are deemed beneficial from the standpoint of 
integration theories, but detrimental according to resource theories.


\subsection{Present study\label{present}}

Our study had two main goals. Firstly, we sought to replicate the TPNL 
effect in an ecologically valid setting, by using complex learning materials 
and standard multiple-choice items. Even though it has been shown that, in 
the standard TPNL procedure, substantially larger effect sizes follow after 
using free recall rather than recognition-level retrieval 
 \citep{chanRetrievalPotentiatesNew2018}, choosing to examine the impact of 
 feedback on TPNL imposed constraints upon our choice of testing format; 
 immediate provision of feedback would have been intractable had we chosen 
 to use free recall. We used multiple-choice questions designed to assess 
 memory both in terms of correct answers and susceptibility to intrusions. 
 Secondly, there is a relative dearth of investigations using nonepisodic 
 retrieval and recognition, and furthermore a lack of studies introducing 
 feedback in a blocked study design 
\citep{chanRetrievalPotentiatesNew2018}. We therefore formed two memory 
tests, one of which tapped into episodic (assessing memory of the studied 
materials) while the other tapped into semantic memory (assessing general 
knowledge). Participants either were or were not given feedback upon 
completing an interpolated activity episode.

Based on the preceding discussion, we predicted that participants in the 
retrieval groups would display TPNL, whereas a control rereading group would 
not. We expected that participants engaging in episodic retrieval would 
display the lowest susceptibility to PI, followed by participants in the 
semantic retrieval condition, and finally by those in the rereading 
condition. We assumed that presenting feedback would have a positive effect 
on memory performance, but only for the participants engaging in episodic 
recall. We also predicted receiving feedback would significantly increase 
interference. Finally, we expected to find an interaction effect of activity 
type and feedback presentation on the number of intrusions, but did not set 
a specific prediction regarding its pattern.
 
{
	\setstretch{1}
	\biblio
}

\end{document}
