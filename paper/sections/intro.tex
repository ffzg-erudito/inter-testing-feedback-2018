\documentclass[../main.tex]{subfiles}

\begin{document}

The term ``testing effect'' refers to the finding that, when it comes to long-term retention of a piece of information, retrieving that information from memory trumps restudying it \citep{roedigeriiiPowerTestingMemory2006, roedigeriiiTestEnhancedLearningTaking2006, rowlandEffectTestingRestudy2014, adesopeRethinkingUseTests2017, roedigeriiiCriticalRoleRetrieval2011, gloverTestingPhenomenonNot1989}. It is generally recognised that testing can have two types of effects --- \textit{direct} and \textit{indirect} \citep{arnoldTestpotentiatedLearningDistinguishing2013, roedigeriiiPowerTestingMemory2006}. Direct effects refer specifically to the increased retention that ensues from repeatedly \textit{successfully} retrieving the target information --- a process which is, presumably, reactivated at the time of a later test. A typical demonstration of the testing effect entails an initial learning phase, followed by a period during which participants either restudy the same material, engage in a memory test involving the studied material, or are not exposed to the original material at all. Finally, after a retention interval, an additional memory test reveals that the group subjected to a memory test during the intervening period has a distinct advantage over the other two groups. 

On the other hand, indirect effects are brought about by some other process or processes besides the act of taking the test (\citealp{roedigeriiiPowerTestingMemory2006}; but for a different view, see \citealp{kornellRetrievalAttemptsEnhance2015}). For example, \textit{unsuccessful} retrieval attempts (which are not followed by feedback) can, through subsequent repeated encoding, also generate a testing effect, namely \textit{test-potentiated (re)learning} \citep{izawaReinforcementTestSequencesPairedAssociate1966,izawaOptimalPotentiatingEffects1970, kornellUnsuccessfulRetrievalAttempts2009, arnoldFreeRecallEnhances2013, arnoldTestpotentiatedLearningDistinguishing2013, wissmanTestpotentiatedLearningThree2018}. With the aim of disentagling test-potentiated (re)learning from the testing effect, \cite{arnoldTestpotentiatedLearningDistinguishing2013} let participants learn a list of 25 word pairs. One group completed nine cycles comprising a single test and a restudy session, while another completed three cycles. In order to isolate the effect of unsuccessful from successful retrieval attempts, they focused their analysis only on words not recalled on a test preceding a restudy episode. Results showed that, compared to taking fewer tests, taking more tests produces a greater increase in the proportion of \textit{newly} retrieved items (i.e. words that were not retrieved on a pretest) in a test immediately following a restudy episode --- a veritable potentiation of learning.

\hypertarget{tpnl}{%
\subsection{Test-potentiated new learningtpnl}}

Juxtaposed to the well established finding that attempting to recall studied material compared to restudying it, facilitates the long-term retention of \textit{that} material, stand the results of a decade of research showing that retrieving previously studied information can even facilitate the acquisition of \textit{new} information \citep{chanRetrievalPotentiatesNew2018, yangEnhancingLearningRetrieval2018}. If each additional study episode in the paradigm used to demonstrate test-potentiated learning contains \textit{new} materials (giving a now standard blocked design; \cite{chanTestingPotentiatesNew2018}), one still observes that testing the memory of those new materials after each learning episode, compared to restudying the same materials, yields a greater number of correct responses and a decrease of proactive interference on a test administered to all subjects after the final learning episode (e.g. \citealp{szpunarInterpolatedMemoryTests2013, szpunarTestingStudyInsulates2008, wissmanInterimTestEffect2011}). Following the reasoning of \cite{chanRetrievalPotentiatesNew2018}, in this paper we will use the term ``test-potentiated \textit{new} learning'' (TPNL) to denote this effect.

In one of the earliest studies showing the effect of TPNL, \cite{darleyEffectsPriorFree1971} observed that, when recalling studied lists of words, participants systematically produce more prior-list intrusions when probed for a given list, if their memory of a prior list had not been tested before they proceeded to study the given list. These findings were corroborated by \cite{tulvingNegativeTransferEffects1974}. Building on these results, \cite{szpunarTestingStudyInsulates2008} conducted a study using a blocked design wherein they told their subjects to study five lists of items in anticipation of a final cumulative test. All subjects were tested immediately after studying the final list, but they engaged in different intermittent activities between studying the first four lists. One group was tested on each list after studying it, another group restudied each list, and a third group completed a mathematical distractor task. Participants whose memory was tested after each list produced more correct responses and fewer prior-list intrusions on the immediate test administered after studying the last list. The authors explained the found benefit of testing in terms of a segregation mechanism that prevents overburdening of retrieval cues, which, in the absence of testing, causes a build-up of proactive interference. The following decade has seen a renewal of interest in TPNL \citep{chanRetrievalPotentiatesNew2018, pastotterRetrievalPracticeEnhances2014, yangEnhancingLearningRetrieval2018}, with studies mainly using the multilist learning paradigm to delineate the scope of the effect with respect to various moderating variables: the type of study materials, varieties of study designs (blocked vs. interleaved), and populations, to name a few. 

\hypertarget{theory}{%
\subsection{Theoretical overview}}

Recently, \cite{chanRetrievalPotentiatesNew2018} provided a meta-analytic analysis and comprehensive overview of the literature, identifying four \textit{nonconflicting} theoretical frameworks which were put forth throughout the years as viable explanations for TPNL. \textit{Resource theories} generally posit that testing increases cognitive resources, but they propose different mechanisms by which this is achieved: (1) proactive interference reduction (e.g. \citealp{wahlheimTestingCanCounteract2015, weinsteinTestingProtectsProactive2011, szpunarTestingStudyInsulates2008, nunesTestingImprovesTrue2012}), (2) restoration of encoding/attentional resources (e.g. \citealp{pastotterRetrievalLearningFacilitates2011}), or (3) alteration of mind wandering patterns (e.g. \citealp{jingInterpolatedTestingInfluences2016,szpunarInterpolatedMemoryTests2013,szpunarMindWanderingEducation2013}). Whereas resource theories focus on the amount of deployable cognitive resources, \textit{metacognitive theories} emphasise the optimisation of encoding strategies induced by retrieval attempts (e.g. \citealp{choTestingEnhancesBoth2017, chanTestingPotentiatesNew2018}). For example, in a recent investigation, \cite{chanTestingPotentiatesNew2018} found that, compared to untested groups, the group whose memory for the first three word lists was subjected to interpolated testing displayed superior semantic organisation across lists. These findigs reflect a similar pattern obtained for the testing effect, where a greater number of tests is associated with improved organisation of output displayed upon testing \citep{karpickeRetrievalBasedLearningActive2012,zarombTestingEffectFree2010}.

The key idea underlying the third framework -- \textit{context theories} -- is that, apart from storing the studied information themselves, people store the related contextual information as well (e.g. \citealp{lehmanEpisodicContextAccount2014}). Afterwards, the accessibility of this contextual information can affect the likelihood of successful retrieval of target information. Furthermore, the claim is that, unlike restudying, attempting retrieval causes an internal context change relative to the study context \citep{jangContextRetrievalContext2008, sahakyanContextualChangeAccount2002}, and recalled items may be updated with contextual information from the retrieval attempt, while newly encountered information is still associated only with the study context. Therefore, recalling new-learning items is limited to only those items associated exclusively with the study context, providing them with the advantage observed upon testing. While this circumscription of separate learning episodes is at the core of both resource and context accounts, its effect on learning is supposedly different. According to the former, isolating a learning episode through attempts at recall increases resources for subsequent learning by preventing \textit{encoding-based} proactive interference. On the other hand, the latter place the emphasis on later \textit{retrieval} processes, whereby isolating an earlier learning episode reduces the memory search set for retrieval.

Finally, \textit{integration theories} advance the notion that interpolated testing facilitates the integration of the new-learning material either with its retrieval cues or with the original-learning material. On one account, testing increases the likelihood of spontaneous covert retrieval of original-learning items during the study of new items, fostering their integration, thereby increasing conceptual organisation (e.g. \citealp{jingInterpolatedTestingInfluences2016}) and the effectiveness of retrieval cues \citep{pycWhyTestingImproves2010}. For example, \cite{jingInterpolatedTestingInfluences2016} found that interpolated testing increased the clustering of related information that is acquired across different segments within a video-recorded lecture.

\hypertarget{nonepisodic}{%
\subsection{Nonepisodic recall}}

One of the more curious findings in the field is that TPNL can arise not only after retrieving the previously studied material (episodic retrieval), but also after retrieval of information unrelated to the studied material from semantic memory \citep{divisRetrievalSpeedsContext2014, pastotterRetrievalLearningFacilitates2011}, or from short-term memory \citep{pastotterRetrievalLearningFacilitates2011}, although there have been unsuccessful attempts at replication (e.g. \citealp{weinsteinNotAllRetrieval2015}).

\cite{pastotterRetrievalLearningFacilitates2011} let their participants learn five lists of 20 words while engaging in varied interlist activities. They either restudied the lists, recalled the words from the list, generated as many words as they could from one of four semantic categories (e.g. professions), engaged in a 2-back short-term memory task, or counted backwards from a random three-digit number. They found that all three forms of retrieval induced TPNL. In their first experiment, \cite{divisRetrievalSpeedsContext2014} adapted the procedure from \cite{pastotterRetrievalLearningFacilitates2011}, using only the semantic generation and distractor (counting backwards) tasks, and found that interleaved semantic retrieval enhanced performance for final list recall. They replicated and extended these findings in their second experiment by using complex learning materials: lists of words were replaced by texts related to animals, while learning was evaluated with short-answer and multiple-choice questions. 

The argument these two groups of authors invoke to explain their results is that nonepisodic retrieval tasks sufficiently alter participant's internal context. Because the last study session is not affected by an additional context shift, a beneficial segregation of the final study context from the previous ones is produced. However, summarising their results, \cite{chanRetrievalPotentiatesNew2018} highlighted resource and integration theories as accounts which have thus far garnered more empirical support, giving a slight upper hand to integration theories, while stating that context theories are least supported by extant research.


\hypertarget{feedback}{%
\subsection{Feedback}}

Although corrective feedback is known to augment the testing effect \citep{roedigeriiiCriticalRoleRetrieval2011}, there is a paucity of research into the effect of feedback on TPNL, especially when considering studies that have implemented the  blocked design. Feedback is particularly important for recognition test such as multiple-choice tests since the usual benefit testing confers might turn into a disadvantage in case the test-taker selects a lure \citep{roedigerPositiveNegativeConsequences2005, marshMemorialConsequencesMultiplechoice2007}. Moreover, evidence points to the timing of feedback being a relevant variable when gauging its influence on learning, with delayed feedback showing superior effects compared to immediate feedback \citep{metcalfeDelayedImmediateFeedback2009,butlerEffectTypeTiming2007, butlerFeedbackEnhancesPositive2008,smithLearningFeedbackSpacing2010}. For example, participants in a study by \cite{butlerFeedbackEnhancesPositive2008} read prose passages and then either took or did not take an initial multiple-choice test. If they took the test, corrective feedback was either not given, given immediately after each answer was provided, or given in bulk after the entire test. A final test administered one week after the initial test revealed (1) that taking an initial test alone tripled the success rate on the final test relative to studying, (2) that giving immediate feedback increased performance for another 10\%, and (3) that delayed feedback increased performance even further by 11\%.

The variable of corrective feedback may be a fruitful avenue for research because resource and integration theories provide conflicting predictions regarding its effects on TPNL \citep{chanRetrievalPotentiatesNew2018}. Providing corrective feedback should increase the likelihood of intrusions during new learning, which are deemed beneficial from the standpoint of integration theories, but detrimental from the point of view of resource theories. Thus, feedback should reduce TPNL according to resource theories, but increase it according to integration theories.


\subsection{Present study\label{present}}

Our study had two main goals. Firstly, we sought to replicate the TPNL effect in
an ecologically valid setting, by using complex learning materials and standard
multiple-choice items. Secondly, guided by the analysis of gaps in the field
provided by \cite{chanRetrievalPotentiatesNew2018}, who identified a relative
dearth of studies using nonepisodic retrieval and recognition (i.e.
multiple-choice items) for the interpolated activity, and furthermore a lack of
studies introducing feedback in a blocked study design, we attempted to expand
the existing body of literature by employing a novel combination of variables,
in order to examine their effects and interactions in the context of TPNL.

In particular, we assumed that retrieval could be the active component in
interpolated activities that have been shown to give rise to TPNL. To test this
we devised two memory testing activities, one of which tapped into episodic
(assessing memory of the studied materials) while the other tapped into semantic
(i.e. nonepisodic) memory (assessing general knowledge).
Furthermore, in order to pit integration
and resources accounts of TPNL against each other, participants either were or
were not given feedback upon completing an interpolated activity episode.

We predicted the following:
\begin{enumerate}[label = \textit{H\arabic*}:]
    \itemsep0pt
    \item Interpolated testing increases the effectiveness of future learning.
        Compared to the rereading group, participants in the retrieval groups
        should have a significantly higher average total score on the final
        test. Furthermore, following the results of some studies, we expect to
        find no difference between the two groups having different types of
        retrieval, which is in accordance with resource theories.
    \item Participants in the content-related test condition will have the
        lowest number of intrusive distractors chosen, followed by participants
        in the general knowledge condition, and finally by the participants in
        the rereading condition. We expect all three differences to be
        statistically significant.
    \item When looking at the two retrieval groups, we
        expect to find a significant main effect of feedback on the average
        number of correctly answered questions.
    \item Furthermore, we expect to find an interaction effect between feedback
        presentation and type of interpolated activity. Specifically, we assume
        that presenting feedback will have a positive effect on the average
        number of correctly answered questions, but only for the participants in
        the content-related test condition. The remaining three groups will not
        differ.
    \item There will be a main effect of feedback on the average number of
        chosen intrusive distractors. Participants receiving feedback will have
        a significantly higher average number of chosen instrusive distractors
        than participants receiving no feedback.
    \item We also expect to find an interaction effect of activity type and
        feedback presentation on the number of intrusive distractors chosen, but
        cannot set a specific hypothesis regarding its pattern.
\end{enumerate}
 
\subsection{Notes for discussion}


Chan et al. (2018). across a retention interval
In contrast to unrelated word lists, text passages and videos are
typically written/produced in a coherent manner, which should naturally
invite relational processing, so any relational processing advantage
induced by prior testing is likely to be modest relative to
%baseline (Einstein, McDaniel, Bowers, & Stevens, 1984; Einstein,
%McDaniel, Owen, & Cote, 1990; Masson & McDaniel, 1981). A version
of the strategy change account that is not tied strictly to relational
processing, however, may provide a reasonable explanation for the
TPNL effect with text passages and videos. In a broader sense, the
strategy change account specifies that performing retrieval practice
allows participants to discover the type of learning needed to ensure
satisfactory performance (or conversely, to realize the type of learning
that is inadequate to produce satisfactory performance, if participants
are performing poorly during retrieval practice), and participants can
then adjust their subsequent encoding strategy accordingly. If we take
this broader approach to strategy change, then this account can explain
the TPNL effect with prose/video materials. However, we realize that
the idea that “retrieval practice can improve later encoding strategies”
is perhaps vaguely defined. In fact, such a broad definition of strategy
change may render the account difficult to falsify. With this in mind, we
believe that the strategy change account, as we currently conceive,
should only be applied to explain the TPNL effect with word list type
materials, for which advantageous encoding strategies can be more
precisely defined (but see Jing et al., 2016 in which interspersed testing
improved conceptual integration of materials across sections of a video
lecture). In our opinion, application of this account to prose/video
material should only be done when one clearly outlines what is considered
an advantageous encoding strategy so that the hypothesis can
be adequately tested.


Možda ZV intruzori nije pokazala razlike između skupina jer smo koristili 
recognition, a ne free recall.
Context change account?






Methodological concerns. The expectation of a final test ensured the
continued processing of materials across the study sequence.
Chan et al. (2018): % za istaknuti mogućnost da su se očekivanja ispitanika dinamički mijenjala tijekom mjerenja
For example, in a multilist learning environment, having taken a
recent memory test increases learners’ expectation that they will
again be tested in the immediate future, even when they are told
that whether a test will follow each study list is determined
randomly (Weinstein et al., 2014). Such test expectancies have
been shown to significantly influence how participants approach
%the encoding task (Balota & Neely, 1980; May & Thompson,
%1989; Szpunar, McDermott, & Roediger, 2007).
Weinstein et al. (2014):
The experiments reported here are based on the assumption that
participants in the tested group may be more likely to expect a test
after the fifth (last) list, having consistently received tests after
previous lists. Those in the untested group, having never received
a test during the experiment until the fifth list test, may therefore
pay less attention or engage in lower quality encoding strategies
during encoding of the fifth list. To test for this alternative explanation, 
we compared the two standard conditions (tested and
untested) with two novel conditions that were identical to the
standard conditions but included a warning before presentation of
the final list to alert participants that they would be tested on the
upcoming list. If attentional processes are mediating the observed
release from proactive interference, warning participants in the
untested group should produce the same benefit as the participants
taking a test after every list


Matej [11:05 PM]
E, sjetio sam se opet da bi možda bilo dobro da negdje navedemo razlike u učinku na testovima prije zadnjega...

Denis [11:09 PM]
Mda, neke te stvari su mi pale na pamet, i činilo mi se kao da bi bilo zgodno spomenuti ih u raspravi. Kao, ako se radi o nekim stvarima koje bi mogle ugroziti efekte ili objasniti neznačajne



Pastötter et al. (2011):
Whereas, relative to the two no-retrieval conditions,
both episodic and semantic memory retrieval effectively
eliminated List 1–4 intrusions during immediate List 5 recall,
short-term memory retrieval led to intrusion rates that were equivalent
in amount to the no-retrieval conditions. This difference in
intrusion errors may suggest that the effects of short-term and
long-term memory retrieval are not perfectly identical.


Yang et al. (2018): za neznačajan efekt na intruzore!
the activation facilitation and enhanced encoding effort mechanisms may play
important roles for complex materials whereas the release from PI
mechanism is likely to play little role.29


Divis i Benjamin (2014)
However, their protocol didn't allow for assessing the contribution of proactive interference to TPNL. Furthermore, the authors argue for the irrelevance of the level of difficulty of alternative activities (i.e. perhaps the semantic retrieval and the distractor tasks were not equal with regards to difficulty) whilst referring to the variety of tasks used by \cite{pastotterRetrievalLearningFacilitates2011}, who found effects of similar magnitude for the retrieval tasks and a lower but approximately equal magnitude for the distractor task and restudy. But it does not follow that these patterns in the data refute an explanation based on task difficulty, i.e. the distractor task and restudy may have been easier than the retrieval tasks. 

{
	\setstretch{1}
	\biblio
}

\end{document}
