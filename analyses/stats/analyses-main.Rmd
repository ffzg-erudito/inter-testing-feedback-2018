---
fontsize: 11pt
geometry: margin=1.8cm
output:
  pdf_document:
    keep_tex: true
    toc: false
header-includes: |
    \usepackage[natbibapa, sectionbib, tocbib]{apacite}
    \usepackage[utf8]{inputenc}
    \usepackage[singlelinecheck = off]{caption}
    \usepackage{lmodern}
    \usepackage{microtype}
    \usepackage{multirow}
    \usepackage[inline]{enumitem}
    \usepackage{array}
    \usepackage[htt]{hyphenat}
    \usepackage{booktabs}
    \usepackage[euler]{textgreek}
    \usepackage{float}
    \usepackage[doublespacing]{setspace}
    \usepackage{fancyhdr}
    \captionsetup[table]{width=\textwidth}
    \setlength{\parindent}{2em}
    \fancyhf{}
    \fancyhead[RH]{\thepage}
    \renewcommand{\headrulewidth}{0pt}
    \pagestyle{fancy}
    \hypersetup{colorlinks = true, linkcolor = blue, urlcolor = black, citecolor = blue}
    \DeclareCaptionFormat{apa}{#1#2\\[1em]#3}
    \captionsetup*[table]{labelsep = none, textfont = it, format = apa, width = .8\textwidth}
    \captionsetup*[figure]{labelsep = period, labelfont = it, position = below}
---

```{r setup, echo = F, include = F}
library(knitr)
opts_chunk$set(dpi = 600, dev = 'tikz', echo = F, include = F)
options(digits = 3, scipen = 12, knitr.kable.NA = '')

library(here)
# NOTE: this will load {magrittr}, {here}, {conflicted} and {tidyverse}. also,
# `conflict_prefer`s filter from {dplyr}
# furthermore, it loads 3 data.frames: (1) `dat` which contains the pooled data run
# through `2-wrangling-main.R`, (2) `datHard` which is `dat` with all the hard
# exclusion criteria applied (as described in `analysis-plan.md`), and (3)
# `datSoft` which is `datHard` with the soft exclusion criteria applied (as
# described in `analysis-plan.md`)
source(here('wrangling', '3-exclusion-criteria.R'))
# for different sums of squares
library(car)
# for tables
library(kableExtra)
# for effect sizes
library(compute.es)
# for bootstrapping
library(boot)
# for Bayesian analyses
library(BayesFactor)
# for extracting HDIs
library(HDInterval)

library(psych)

conflict_prefer('select', 'dplyr')
theme_set(theme_minimal())

# source helper functions
source(here('helpers', 'manova-helpers.R'))

apaPrint <- function(number, pvalue = F, digits = 3,
                     limit = .0001, replacement = '.0001') {
  if (pvalue & number < limit) {
    replacement
  } else {
    strCandidate <- round(number, digits = digits) %>%
    {str_replace(as.character(.), '(?<=[-+]?)0(?=\\.)', '')}
    if (str_length(strCandidate) < digits + 1) {
      str_pad(strCandidate, 'right', pad = '0', width = digits + 1)
    } else strCandidate
  }
}
```

## Exclusion criteria

```{r descTable, results = 'asis', include = T}
.a <- by(datHard$totalCorrect, datHard$condition, describe) %>%
  map_dfr(., rbind) %>%
  select(., n, mean, se, sd, min, max)
  
.b <- by(datHard$totalIntrusors, datHard$condition, describe) %>%
  map_dfr(., rbind) %>%
  select(., n, mean, se, sd, min, max)
  
rbind(.a, .b) %>%
  rename(., '$n$' = n, '$M$' = mean, '$SE_M$' = se, '$SD$' = sd) %>%
  cbind(Measure = c(rep('Total correct', 5), rep('Total intrusors', 5)),
        Condition = rep(c("Content, feedback", "Content, no feedback",
                          "General, feedback", "General, no feedback",
                          "Rereading")), .) %>% 
  kable(., caption = '\\label{descTable}Descriptive statistics for the DVs broken down
                     by experimental condition.',
        format = 'latex', booktabs = T, table.env = 'table*',
        digits = 3, escape = F) %>% 
  collapse_rows(., columns = 1, latex_hline = 'major') %>% 
  kable_styling(latex_options = c('hold_position'))
```

Prior to analysing the data, we excluded participants based on a priori
set criteria. Participants who spent less than or equal to 90 seconds
on the practice text were excluded
(`r nrow(dat) - dat %>% filter(., readingTime > 90) %>% nrow(.)` exclusion).
Further, we wanted to exclude participants who had no correct answers on
the final test
(`r dat %>% filter(., readingTime > 90) %>% nrow(.) -
{dat %>% filter(., readingTime > 90 & totalCorrect > 0) %>% nrow(.)}` exclusions).
Finally, we excluded participants who had stated that they had reading
deficits
(`r dat %>% filter(., readingTime > 90 & totalCorrect > 0) %>% nrow(.) -
{dat %>% filter(., readingTime > 90 & totalCorrect > 0 &
readingDeficits == 'NE')%>% nrow(.)}` exclusions). This left us with a total sample
of `r nrow(datHard)` participants. The descriptives for the sample are shown
in Table \ref{descTable}.

## Interpolated activity effect

```{r datHardNofeedFilter}
datHardNofeed <- datHard %>% filter(., giveFeedback == F) %>%
  select(., activityFactor, totalCorrect, totalIntrusors)
datHardNofeed$activityFactor %<>% as.factor(.)
```

Our first two hypotheses are concerned with the effects of different interpolated
activities on the total number of correct answers and total number of intrusive
distractors chosen. To test these hypotheses, we focused only on the groups
which did not receive feedback (\(n\) = `r nrow(datHardNofeed)`).
This was done because there was no feedback option for the rereading group, and
we did not want to treat the feedback and no-feedback general-knowledge and
content-related testing groups as equivalent without strong evidence supporting
that assumption.

The correlation between our DVs calculated on the
whole sample is \(r(`r nrow(datHard) - 2`) =\)
`r datHard %>% select(totalCorrect, totalIntrusors) %>% corr.test(.) -> .;
pluck(., 'r') %>% .[1,2] %>% apaPrint(.)`
(95% CI: [`r pluck(., 'ci') %>% pull(lower) %>% apaPrint(.)`,
`r pluck(., 'ci') %>% pull(upper) %>% apaPrint(.)`],
\(p\) < `r datHard %>% select(totalCorrect, totalIntrusors) %>% corr.test(.) -> .;
pluck(., 'p') %>% .[1,2] %>% apaPrint(., pvalue = T)`).
Given that we have two dependent variables, which are highly correlated, we have
decided to conduct a one-way MANOVA. According to 
\citet{tabachnickUsingMultivariateStatistics2012}, conducting a MANOVA instead of
multiple ANOVAs increases the chance of discovering the effects of different
treatments. Furthermore conducting a MANOVA guards against the inflation of
Type 1 errors due to multiple tests of correlated dependent variables
\citep{tabachnickUsingMultivariateStatistics2012,fieldDiscoveringStatisticsUsing2012}.
Finally, conducting separate ANOVAs would disregard the correlation between our
two dependent variables \citep{fieldDiscoveringStatisticsUsing2012}.
Therefore, we conducted a one-way MANOVA with interpolated activity as
the independent variable and the total number of correct and intrusive options
chosen as dependent variables. 

A power analysis conducted prior to analyzing the data
\citep[using the G*Power software by][]{faulStatisticalPowerAnalyses2009}
has shown that we should have above 80% power to detect effects which fall
between small and medium (Cohen's \(f^2\ \gtrsim 0.06\)), at an \(\alpha\) level
of .025, with a sample size of 110 participants.
Note that larger effects are expected based on prior studies.

```{r manovaInterpActivity}
manovaModel <- manova(data = datHardNofeed,
                      cbind(totalCorrect, totalIntrusors) ~ activityFactor)
```

```{r manovaBoot, cache = T}
set.seed(1192017)

bootOmega <- function(data, i) {
  d <- data[i,]
  
  bootManova <- manova(data = d,
                       cbind(totalCorrect, totalIntrusors) ~
                         activityFactor)
  
  manovaSummary <- summary(bootManova, test = 'Wilks')
  
  omSq <- omegaSquared(nrow(bootManova$residuals), manovaSummary$stats[1, 'Wilks'],
               manovaSummary$stats[1, 'Df']) 
  
  return(omSq)
}

bootOut <- boot(datHardNofeed, statistic = bootOmega, R = 10000,
                parallel = 'multicore', ncpus = parallel::detectCores() - 1)

ciOut <- boot.ci(bootOut, index = 1)

cohensF2r <- sqrt((2^2 * (3 - 1)^2 - 4) / (2^2 + (3 - 1)^2 - 5))

cohensF2u <- 2 * (3 - 1)

cohensF2w <- nrow(datHardNofeed) - (2 + 3) / 2 - 1

cohensF2v <- cohensF2w * cohensF2r + 1 - cohensF2u / 2

cohensF2 <- manovaStats(manovaModel, 'test',
                        '^activityFactor ',
                        test = 'Wilks')^(-1 / cohensF2r) *
                          (cohensF2v / (cohensF2v + cohensF2u)) - 1
```

Pillai's V for the analysis is
`r summary(manovaModel) %>% pluck(., 'stats') %>% .[1, 'Pillai'] %>% apaPrint(.)`,
\(p = `r summary(manovaModel) %>% pluck(., 'stats') %>% .[1, 'Pr(>F)'] %>%
apaPrint(., pvalue = T)`\)
(Wilks' \(\Lambda\) =
`r summary(manovaModel, test = 'Wilks') %>% pluck(., 'stats') %>% .[1, 'Wilks'] %>%
apaPrint(.)`,
\(p = `r summary(manovaModel, test = 'Wilks') %>% pluck(., 'stats') %>% .[1, 'Pr(>F)'] %>%
apaPrint(., pvalue = T)`\)).
The effect size, calculated as
\(\omega^2_{mult} = `r summary(manovaModel, test = 'Wilks') -> .;
omegaSquared(nrow(manovaModel$residuals), .$stats[1, 'Wilks'], .$stats[1, 'Df']) %>%
apaPrint(.)`\)
(bootstrap median\footnote{All bootstrap estimates taken from 10000 replications.} = `r bootOut$t %>% median(.) %>% apaPrint(.)`, \(BC_\alpha\) 95% CI =
[`r ciOut$bca[4] %>% apaPrint(.)`, `r ciOut$bca[5] %>% apaPrint(.)`])\footnote{
Cohen's \(f^2 = `r cohensF2`\) (calculated according to Equation 12 in
\citealp{steynjrEstimatingEffectSize2009}).
}.
To further inspect the relationship of the interpolated activities with our
dependent variables, we conducted a Roy-Bargmann stepdown analysis, as
suggested by \citeauthor{tabachnickUsingMultivariateStatistics2012}
(\citeyear{tabachnickUsingMultivariateStatistics2012};
a linear discriminant analysis with the same aim is available in the supplementary
materials).
According to \citet{tabachnickUsingMultivariateStatistics2012},
the higher priority variable can be chosen based on theoretical or practical grounds.
Since the total number of correct answers is the criterion that determines a
student's success in a testing context, we chose this dependent variable
as the higher priority one.
Therefore, we first conducted an ANOVA with interpolated
activity type as the independent variable and the total number of correct answers
as the dependent variable.

```{r royBargmann1}
# anova
anovaRB <- aov(totalCorrect ~ activityFactor, datHardNofeed)
anovaRB %<>% Anova(.) %>% broom::tidy(.)

# ancova with totalCorrect as covariate
ancovaRB <- aov(totalIntrusors ~ totalCorrect + activityFactor, datHardNofeed)
ancovaRB %>% Anova(., type = '3') %>% broom::tidy(.) -> .
```

As could be expected, the ANOVA points to a differential effect of our
conditions on the total number of correct answers, with
\(F(`r anovaRB %>% filter(., term == 'activityFactor') %>% pull(., df)`,
`r anovaRB %>% filter(., term == 'Residuals') %>% pull(., df)`)\) =
`r anovaRB %>% select(., statistic) %>% slice(1) %>% apaPrint(.)`,
\(p = `r anovaRB %>% select(., p.value) %>% slice(1) %>% apaPrint(., pvalue = T)`\).
Following the ANOVA, we conducted an ANCOVA, with
the total number of correct answers as the covariate, and the total number of intrusors
as the dependent variable. The results imply a main effect
of the total number of correct answers
(\(F(`r (.) %>% filter(., term == 'totalCorrect') %>% pull(df)`,
`r (.) %>% filter(., term == 'Residuals') %>% pull(df)`)\) =
`r (.) %>% filter(., term == 'totalCorrect') %>% pull(statistic)`,
\(p < `r (.) %>% filter(., term == 'totalCorrect') %>% pull(p.value) %>%
apaPrint(., pvalue = T)`\)),
but after we took into account the number of correct
answers, we found no evidence for an effect of interpolated activity type
on the total number of chosen intrusors
(\(F (`r (.) %>% filter(., term == 'activityFactor') %>% pull(df)`,
`r (.) %>% filter(., term == 'Residuals') %>% pull(df)`)\) =
`r (.) %>% filter(., term == 'activityFactor') %>% pull(statistic)`,
\(p = `r (.) %>% filter(., term == 'activityFactor') %>% pull(p.value) %>%
apaPrint(., pvalue = T)`\)).
Thus far, results point to a lack of evidence to support our second hypothesis
that the type of interpolated activity will have an effect on the number of
intrusors.

```{r contrastsH1}
contrastMatrix <- matrix(c(1, 1, -2, 1, -1, 0), 3, 2)
colnames(contrastMatrix) <- c('test vs rereading', 'content vs general')

anovaContrastH1 <- aov(totalCorrect ~ activityFactor, datHardNofeed,
                       contrasts = list(activityFactor = contrastMatrix))
anovaContrastH1 %>% summary.lm(.) %>% broom::tidy(.) -> .

esCont1 <- tes((.) %>% select(., statistic) %>% slice(2) %>% as.integer(.),
               datHardNofeed %>% tally(., activityFactor == 'rereading') %>%
                 as.integer(.),
               datHardNofeed %>% tally(., activityFactor != 'rereading') %>%
                 as.integer(.))

esCont2 <- tes((.) %>% select(., statistic) %>% slice(3) %>% as.integer(.),
               datHardNofeed %>% tally(., activityFactor == 'content') %>%
                 as.integer(.),
               datHardNofeed %>% tally(., activityFactor == 'general') %>%
                 as.integer(.))

```

In order to test our first hypothesis, we contrasted
(i) the rereading group with the two test groups, and (ii) the two test groups with
each other, taking only the total number of correct answers as the DV.
The first contrast found no evidence of a difference between the rereading group
and the two test groups
(\(t(`r summary.lm(anovaContrastH1) %>% pluck('df') %>% .[2]`)\) =
`r (.) %>% select(statistic) %>% slice(2) %>% apaPrint(.)`,
\(p = `r (.) %>% select(p.value) %>% slice(2) %>% apaPrint(., pvalue = T)`\),
\(g_s\) = `r esCont1$g`, 95% CI = [`r esCont1$l.g`, `r esCont1$u.g`],
Cohen's \(U_{3, g_s}\) = `r esCont1$U3.g`%,
probability of superiority = `r esCont1$cl.g`%).
Therefore, we cannot conclude that being in the rereading condition, as
opposed to being in one of the two test groups, leads to different learning
outcomes.
However, there was a difference between the two test groups
(\(t(`r summary.lm(anovaContrastH1) %>% pluck('df') %>% .[2]`)\) =
`r (.) %>% select(statistic) %>% slice(3) %>% apaPrint(.)`,
\(p = `r (.) %>% select(p.value) %>% slice(3) %>% apaPrint(., pvalue = T, digits = 4)`\),
\(g_s\) = `r esCont2$g`, 95% CI = [`r esCont2$l.g`, `r esCont2$u.g`],
Cohen's \(U_{3, g_s}\) = `r esCont2$U3.g`%,
probability of superiority = `r esCont2$cl.g`%).
Participants in the content related test group scored higher on the final test
than participants in the general knowledge test condition.
These two findings are not in line with our predictions.

## The interaction between feedback and interpolated activity type

```{r datHardFeedFilter}
datHardFeed <- datHard %>% filter(., condition != 'rereading') %>%
  select(., condition, giveFeedback, activityFactor,
         totalCorrect, totalIntrusors)

datHardFeed %<>% mutate_at(., vars(activityFactor, giveFeedback, condition),
                           as.factor)
```

The remaining hypotheses deal with the effect of feedback on the total number of
correct answers and the total number of intrusors. Therefore, these analyses were
carried out on the data from participants in the general and content related
test conditions only (\(n\) = `r nrow(datHardFeed)`). 
To test these hypotheses, we first
conducted a two-way MANOVA with interpolated activity and feedback as independent
variables, and total number of correct answers and total number of intrusors as
the dependent variables. Again, a power analysis conducted before analysing the
data has shown that we should have above 80% power to detect effects which fall
between small and medium (Cohen's \(f^2\ \gtrsim 0.05\)), at an \(\alpha\)
level of .025, with a sample size of 145 participants.

```{r manovaInteraction}
manovaModelInter <- manova(cbind(totalCorrect, totalIntrusors) ~
                             activityFactor * giveFeedback,
                           data = datHardFeed)
```

```{r manovaBootActivity, cache = T}
set.seed(1912017)

bootOmegaActivity <- function(data, i) {
  d <- data[i,]
  
  bootManova <- manova(data = d,
                       cbind(totalCorrect, totalIntrusors) ~
                         activityFactor * giveFeedback)
  
  omSq <- omegaSquared(nrow(bootManova$residuals),
                       manovaStats(bootManova, 'test', '^activityFactor ',
                                   test = 'Wilks'),
                       manovaStats(bootManova, 'df', '^activityFactor ',
                                   test = 'Wilks')) 
  
  return(omSq)
}

bootOutActivity <- boot(datHardFeed, statistic = bootOmegaActivity,
                        R = 10000, parallel = 'multicore',
                        ncpus = parallel::detectCores() - 1)

ciOutActivity <- boot.ci(bootOutActivity, index = 1)
```

Pillai's V for the interpolated activity effect (calculated with type III sums of
squares) is 
`r manovaStats(manovaModelInter, 'test', '^activityFactor ') %>% apaPrint(.)`,
\(p = `r manovaStats(manovaModelInter, 'p', '^activityFactor ') %>% apaPrint(., pvalue = T)`\)
(Wilks' \(\Lambda\) =
`r manovaStats(manovaModelInter, 'test', '^activityFactor ', test = 'Wilks') %>%
apaPrint(.)`,
\(p = `r manovaStats(manovaModelInter, 'p', '^activityFactor ', test = 'Wilks') %>%
apaPrint(., pvalue = T)`\))
confirming the main effect of interpolated activity type.
The effect size
\(\omega^2_{mult}\) = `r omegaSquared(nrow(manovaModelInter$residuals),
manovaStats(manovaModelInter, 'test', '^activityFactor ', test = 'Wilks'),
manovaStats(manovaModelInter, 'df', '^activityFactor ', test = 'Wilks')) %>%
apaPrint(.)`
(bootstrap median = `r bootOutActivity$t %>% median(.) %>% apaPrint(.)`,
\(BC_\alpha\) 95% CI = [`r ciOutActivity$bca[4] %>% apaPrint(.)`,
`r ciOutActivity$bca[5] %>% apaPrint(.)`]).

```{r manovaBootFeed, cache = T}
set.seed(1171017)

bootOmegaFeed <- function(data, i) {
  d <- data[i,]
  
  bootManova <- manova(data = d,
                       cbind(totalCorrect, totalIntrusors) ~
                         activityFactor * giveFeedback)
  
  omSq <- omegaSquared(nrow(bootManova$residuals),
                       manovaStats(bootManova, 'test', '^giveFeedback ',
                                   test = 'Wilks'),
                       manovaStats(bootManova, 'df', '^giveFeedback ',
                                   test = 'Wilks')) 
  
  return(omSq)
}

bootOutFeed <- boot(datHardFeed, statistic = bootOmegaFeed,
                           R = 10000, parallel = 'multicore',
                           ncpus = parallel::detectCores() - 1)

ciOutFeed <- boot.ci(bootOutFeed, index = 1)
```

On the other hand, we found no evidence for an effect of giving feedback on the linear combination of
our two dependent variables --- Pillai's V =
`r manovaStats(manovaModelInter, 'test', '^giveFeedback ') %>% apaPrint(.)`,
\(p = `r manovaStats(manovaModelInter, 'p', '^giveFeedback ') %>% apaPrint(., pvalue = T)`\)
(Wilks' \(\Lambda\) =
`r manovaStats(manovaModelInter, 'test', '^giveFeedback ', test = 'Wilks') %>%
apaPrint(.)`,
\(p = `r manovaStats(manovaModelInter, 'p', '^giveFeedback ', test = 'Wilks') %>%
apaPrint(., pvalue = T)`\)).
The effect size is
\(\omega^2_{mult}\) = `r omegaSquared(nrow(manovaModelInter$residuals),
manovaStats(manovaModelInter, 'test', '^giveFeedback ', test = 'Wilks'),
manovaStats(manovaModelInter, 'df', '^giveFeedback ', test = 'Wilks')) %>%
apaPrint(.)`
(bootstrap median = `r bootOutFeed$t %>% median(.) %>% apaPrint(.)`\footnote{
The \(BC_\alpha\) 95\% CI for this estimate is \([`r ciOutFeed$bca[4] %>% apaPrint(.)`,
`r ciOutFeed$bca[5] %>% apaPrint(.)`]\).
\label{bca-ref}}).

```{r manovaBootInt, cache = T}
set.seed(1171717)

bootOmegaInt <- function(data, i) {
  d <- data[i,]
  
  bootManova <- manova(data = d,
                       cbind(totalCorrect, totalIntrusors) ~
                         activityFactor * giveFeedback)
  
  omSq <- omegaSquared(nrow(bootManova$residuals),
                       manovaStats(bootManova, 'test', '^activityFactor:',
                                   test = 'Wilks'),
                       manovaStats(bootManova, 'df', '^activityFactor:',
                                   test = 'Wilks')) 
  
  return(omSq)
}

bootOutInt <- boot(datHardFeed, statistic = bootOmegaInt,
                           R = 10000, parallel = 'multicore',
                           ncpus = parallel::detectCores() - 1)

ciOutInt <- boot.ci(bootOutInt, index = 1)
```

Furthermore, we found no evidence for an interaction effect between activity type
and feedback --- Pillai's V =
`r manovaStats(manovaModelInter, 'test', '^activityFactor:') %>% apaPrint(.)`,
\(p = `r manovaStats(manovaModelInter, 'p', '^activityFactor:') %>%
apaPrint(., pvalue = T)`\)
(Wilks' \(\Lambda\) =
`r manovaStats(manovaModelInter, 'test', '^activityFactor:', test = 'Wilks') %>%
apaPrint(.)`,
\(p = `r manovaStats(manovaModelInter, 'p', '^activityFactor:', test = 'Wilks') %>%
apaPrint(., pvalue = T)`\)).
The effect size
\(\omega^2_{mult}\) = `r omegaSquared(nrow(manovaModelInter$residuals),
manovaStats(manovaModelInter, 'test', '^activityFactor:', test = 'Wilks'),
manovaStats(manovaModelInter, 'df', '^activityFactor:', test = 'Wilks')) %>%
apaPrint(.)`
(bootstrap median = `r bootOutInt$t %>% median(.) %>% apaPrint(.)`\footnote{
The \(BC_\alpha\) 95\% CI = \([`r ciOutInt$bca[4] %>% apaPrint(.)`,
`r ciOutInt$bca[5] %>% apaPrint(.)`]\).
Our guess is that this odd result is due to the fact that most of the density is concentrated
around 0, causing an unreliable estimate. The same could be said for the CI in
footnote \ref{bca-ref}.}). Both the feedback and the interaction
estimates of \(\omega^2_{mult}\) are to be considered to be zero, given their negative values.

```{r royBargmann2}
anovaRB2 <- aov(totalCorrect ~ activityFactor * giveFeedback,
                data = datHardFeed)

Anova(anovaRB2, type = '3') %>% broom::tidy(.) -> rbAnova2

ancovaRB2 <- aov(totalIntrusors ~ activityFactor * giveFeedback * totalCorrect,
                 data = datHardFeed)

Anova(ancovaRB2, type = '3') %>% broom::tidy(.) -> rbAncova2
```

Again, we conducted a follow-up Roy-Bargmann stepdown analysis. In the ANOVA
model with the total number of correct answers as the dependent variable and
the type of interpolated activity, feedback and their interaction as predictors,
only the type of activity seems to be relevant
(\(F(`r rbAnova2 %>% slice(2) %>% pull(df)`,
`r rbAnova2 %>% slice(5) %>% pull(df)`) =
`r rbAnova2 %>% slice(2) %>% pull(statistic)`, p =
`r rbAnova2 %>% slice(2) %>% pull(p.value) %>% apaPrint(., pvalue = T)`\)).
This result also shows that participants in the content related test condition
scored higher on the final test than the participants in the general knowledge test
condition, which should be no surprise given the results of the first stepdown analysis.
In the second step, we fit an ANCOVA model with the total number of correct answers
as the covariate. In this model, the type of interpolated activity ceases to be
a relevant predictor
(\(F(`r rbAncova2 %>% slice(2) %>% pull(df)`,
`r rbAncova2 %>% slice(9) %>% pull(df)`) =
`r rbAncova2 %>% slice(2) %>% pull(statistic)`, p
= `r rbAncova2 %>% slice(2) %>% pull(p.value) %>% apaPrint(., pvalue = T)`\)).
The full models are shown in Table \ref{rb2-table}.

To summarise, contrary to our expectations, we find no evidence of an effect of
feedback on the total number of correctly answered questions. Also, we found no
evidence for an interaction effect of feedback and type of interpolated
activity on the total number of correct answers. The same findings apply to the
predictions regarding the total number of intrusors chosen.

```{r rb2Table, results = 'asis', include = T}
rbind(rbAnova2, rbAncova2) %>% filter(., !str_detect(term, 'Intercept')) %>%
  mutate_at(., vars(term), str_replace_all,
            'activityFactor', 'Activity') %>%
  mutate_at(., vars(term), str_replace_all,
            'giveFeedback', 'Feedback') %>%
  mutate_at(., vars(term), str_replace_all,
            'totalCorrect', 'Total correct') %>%
  mutate_at(., vars(term), str_replace_all,
            ':', ' x ') %>%
  modify_at(., 'p.value', map_chr,
            function(x) {
              ifelse(is.na(x), '', apaPrint(x, pvalue = T,
                                           replacement = '< .0001'))
            }) %>%
  rename('Term' = term, '$SS$' = sumsq, '$df$' = df,
              '$F$' = statistic, '$p$' = p.value) %>%
  kable(., caption = '\\label{rb2-table}ANOVA and ANCOVA models for the second Roy-Bargmann
                     procedure.',
        format = 'latex', booktabs = T, table.env = 'table*',
        digits = 3, escape = F, align = c('l', rep('r', 4))) %>%
  kable_styling(., latex_options = c('hold_position')) %>%
  pack_rows(index = c('ANOVA' = 4, 'ANCOVA' = 8))
```

## Deviations from the preregistered analysis plan

Initially, we had planned to do a robustness check of our findings using
data with an additional exclusion criterion, based on the number of times
each participant had read each of the three parts of the main text. This analysis
was never conducted because (i) applying this criterion would have lead to
unacceptably low power and (ii) the participants' estimates of the number
of times they had read each part were similarly distributed across all conditions.
Further, we had planned to conduct a TOST procedure to test whether there is
no difference between the content-related and general-knowledge testing
groups. This analysis was not conducted because we did find a difference.
A Bayesian t-test was also considered for the same comparison, but was dropped
early on due to some conceptual concerns.
